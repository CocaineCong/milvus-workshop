{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a72e819-546c-4828-ad23-5492b8b18ab5",
   "metadata": {},
   "source": [
    "# 3.3 Milvus 在 AI Agent 中的应用\n",
    "\n",
    "在本节中，我们将探讨 AI Agent 的基本架构，Milvus 如何在其中扮演关键角色，并通过一个使用 LangGraph 和 Milvus 构建的 Agent 案例来演示其实际应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092474d-bb4e-46d1-bbae-4e838442dff5",
   "metadata": {},
   "source": [
    "## AI Agent 架构概览\n",
    "\n",
    "一个典型的 AI Agent 通常由以下几个核心组件构成：\n",
    "\n",
    "*   **Planning (规划):**\n",
    "    *   **目标设定与分解:** Agent 首先需要理解用户的最终目标，并将其分解为一系列可执行的子任务或步骤。\n",
    "    *   **策略选择:** 对于每个子任务，Agent 可能有多种执行方式或工具可以选择。规划模块负责选择最优策略。\n",
    "    *   **执行监控与调整:** 在任务执行过程中，Agent 需要监控进展，并根据实际情况调整计划。例如，如果一个步骤失败，它可能需要重新规划或尝试其他方法。\n",
    "\n",
    "*   **Memory (记忆):**\n",
    "    *   **短期记忆 (Short-term Memory):** 用于存储当前对话的上下文、最近的交互信息或正在处理的任务的中间状态。这对于保持对话连贯性和多轮交互至关重要。\n",
    "    *   **长期记忆 (Long-term Memory):** 用于存储 Agent 学习到的知识、过去的经验、用户偏好、成功的解决方案等。这使得 Agent 能够从过去的交互中学习，并随着时间的推移变得更加智能和个性化。\n",
    "\n",
    "*   **Tools (工具):**\n",
    "    *   **功能调用:** Agent 可以使用各种工具来完成特定任务。这些工具可以是：\n",
    "        *   **API 调用:** 例如，搜索天气、查询数据库、发送邮件等。\n",
    "        *   **代码执行:** 执行 Python 脚本或其他代码片段来处理数据或执行复杂计算。\n",
    "        *   **知识库查询:** 从外部知识库（如 Milvus）中检索信息。\n",
    "    *   **工具选择与使用:** Agent 的规划模块需要决定何时使用哪个工具，以及如何将工具的输出整合到其任务执行流程中。\n",
    "\n",
    "这种架构使得 AI Agent 能够像一个智能助手一样，理解任务、制定计划、利用可用资源（工具和记忆），并最终完成目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf09f1-6ded-4556-9da7-7245a6d93e53",
   "metadata": {},
   "source": [
    "## Milvus 在 Agent 中的角色\n",
    "\n",
    "Milvus 作为一个高性能的向量数据库，在 AI Agent 中可以扮演两个至关重要的角色：\n",
    "\n",
    "### 1. External Knowledge Base (外部知识库)\n",
    "\n",
    "*   **功能:** Agent 经常需要访问和查询大量的外部信息来回答问题或完成任务。这些信息可以是非结构化的文本数据、文档、网页内容等。\n",
    "*   **Milvus 的作用:**\n",
    "    *   **存储:** 将这些外部信息通过 Embedding 模型转化为向量，并存储在 Milvus 中。\n",
    "    *   **检索:** 当 Agent 需要相关信息时，它可以将用户的查询或其内部思考也转化为向量，然后在 Milvus 中进行高效的相似性搜索，快速找到最相关的知识片段。\n",
    "    *   **类似 RAG:** 这种模式与检索增强生成 (Retrieval Augmented Generation, RAG) 非常相似。Milvus 作为 RAG 架构中的核心检索引擎，为 Agent 提供准确、相关的上下文信息，从而提升其回答的质量和事实性。\n",
    "\n",
    "### 2. Memory (记忆)\n",
    "\n",
    "*   **功能:** Agent 需要记住过去的交互、学习到的经验、成功的规划步骤等，以便在未来的任务中更好地执行。\n",
    "*   **Milvus 的作用:**\n",
    "    *   **存储对话历史:** Agent 的对话历史（用户提问、Agent 回答、中间思考）可以被向量化并存储在 Milvus 中。\n",
    "    *   **存储学习经验:** Agent 在执行任务过程中学习到的成功策略、失败教训、用户偏好等，都可以转化为向量形式存储起来。\n",
    "    *   **存储规划步骤:** 复杂的任务规划过程中的中间步骤和决策逻辑，也可以向量化后存入 Milvus，供未来相似任务参考。\n",
    "    *   **快速召回:** 当 Agent 开始新的对话或任务时，它可以查询 Milvus 中存储的记忆向量，找到与当前情境最相似的历史记录或经验，从而快速回忆相关信息，提供更连贯、个性化和高效的服务。\n",
    "\n",
    "通过将信息向量化并存储在 Milvus 中，Agent 可以利用语义相似性来检索知识和记忆，而不仅仅是关键词匹配，这使得 Agent 的信息获取和利用能力大大增强。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf55a83-92e3-4800-ab6f-961d4817102d",
   "metadata": {},
   "source": [
    "## 案例演示/代码讲解：一个使用 LangGraph 和 Milvus 的 Agent\n",
    "\n",
    "接下来，我们将通过一个简化的案例，演示一个 AI Agent 如何利用 Milvus 作为外部知识库。我们将使用 LangGraph 来构建 Agent 的控制流程。\n",
    "\n",
    "**核心流程：**\n",
    "\n",
    "1.  **用户提问:** 用户向 Agent 提出一个问题。\n",
    "2.  **Agent 规划 (识别需求):** Agent (通过 LLM) 分析问题，判断是否需要从外部知识库 (Milvus) 中获取信息。\n",
    "3.  **查询向量化:** 如果需要，Agent 将用户的查询或其衍生的搜索关键词转化为向量。\n",
    "4.  **Milvus 搜索:** Agent 使用该向量在 Milvus 中搜索相关的知识。\n",
    "5.  **获取信息:** Milvus 返回最相关的文档片段。\n",
    "6.  **Agent 整合信息并响应:** Agent 结合从 Milvus 获取的信息和自身的推理能力，生成最终答案给用户。\n",
    "\n",
    "**同时，我们也可以构想 Agent 如何存储对话片段：**\n",
    "\n",
    "1.  **对话结束/片段记录:** 在对话的某个节点（例如，一轮问答结束），Agent 将该对话片段（用户问题、Agent 回答、可能还有一些上下文元数据）进行向量化。\n",
    "2.  **存入 Milvus 记忆库:** 将这个向量及对应的文本内容存入一个专门的 Milvus 集合（或特定分区）作为长期记忆。\n",
    "3.  **新对话开始时召回:** 当新的对话开始，或用户提出一个模糊的问题时，Agent 可以将当前输入向量化，在 Milvus 记忆库中搜索相似的历史对话，从而快速理解用户意图或提供更个性化的回应。\n",
    "\n",
    "**下面我们聚焦于使用 Milvus 作为外部知识库的 LangGraph Agent 实现。**\n",
    "\n",
    "我们将简化上述参考链接中的 GraphRAG 概念，构建一个更直接的 Agent，它有一个工具是查询 Milvus。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90d7f3f-039d-4d39-9965-3ca7c648a6de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymilvus in /home/ec2-user/.local/lib/python3.9/site-packages (2.5.8)\n",
      "Requirement already satisfied: langchain in /home/ec2-user/.local/lib/python3.9/site-packages (0.1.20)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: langchain_openai in /home/ec2-user/.local/lib/python3.9/site-packages (0.0.2.post1)\n",
      "Requirement already satisfied: langchain_community in /home/ec2-user/.local/lib/python3.9/site-packages (0.0.38)\n",
      "Requirement already satisfied: sentence-transformers in /home/ec2-user/.local/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: setuptools>69 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (70.1.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (1.63.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (5.27.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (1.0.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (2.2.2)\n",
      "Requirement already satisfied: milvus-lite>=2.4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from pymilvus) (2.4.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (0.1.81)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain) (8.4.1)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.69-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.6.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain_openai) (1.51.0)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain_openai) (0.5.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/.local/lib/python3.9/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/.local/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "INFO: pip is looking at multiple versions of langgraph-checkpoint to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.22-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.21-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.20-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.19-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.18-py3-none-any.whl.metadata (4.6 kB)\n",
      "INFO: pip is still looking at multiple versions of langgraph-checkpoint to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langgraph_checkpoint-2.0.17-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.15-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.14-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.13-py3-none-any.whl.metadata (4.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langgraph_checkpoint-2.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langgraph_checkpoint-2.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.4.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.3.34-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.3.33-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.3.32-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading langgraph-0.3.30-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.29-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.28-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.27-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.26-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.24-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.23-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.22-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.21-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.19-py3-none-any.whl.metadata (7.7 kB)\n",
      "  Downloading langgraph-0.3.18-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.17-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.16-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.15-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.14-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.13-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.11-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.10-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.9-py3-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading langgraph-0.3.8-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.6-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.5-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.4-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.3-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.3.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.76-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: pip is looking at multiple versions of langgraph to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langgraph-0.2.75-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.73-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.72-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.71-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.70-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading langgraph-0.2.69-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: pip is still looking at multiple versions of langgraph to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langgraph-0.2.68-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading langgraph-0.2.67-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading langgraph-0.2.66-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading langgraph-0.2.65-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading langgraph-0.2.64-py3-none-any.whl.metadata (16 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langgraph-0.2.63-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.62-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.61-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.60-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.59-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.58-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.57-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.56-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.55-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.54-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.53-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.52-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.51-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.50-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.49-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.48-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.47-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.46-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.45-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.44-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.43-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading langgraph-0.2.42-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.41-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.40-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.39-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.38-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.37-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.36-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.35-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.34-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.33-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.32-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.28-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.27-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.26-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.25-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.24-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.23-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.21-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.20-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.19-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.18-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.17-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.16-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.15-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.14-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.13-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.12-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.11-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.10-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.9-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.8-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.10-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.9-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading langgraph-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.1.4-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.0.69-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.0.68-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.0.67-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading langgraph-0.0.66-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.65-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.64-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.63-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.62-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.61-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.60-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.59-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.58-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.57-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.56-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.55-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.54-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.53-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.52-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading langgraph-0.0.51-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uuid6<2025.0.0,>=2024.1.12 (from langgraph)\n",
      "  Downloading uuid6-2024.7.10-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/.local/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/.local/lib/python3.9/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/ec2-user/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.6.1->langchain_openai) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.15.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Downloading langgraph-0.0.51-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uuid6-2024.7.10-py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: uuid6, langgraph\n",
      "Successfully installed langgraph-0.0.51 uuid6-2024.7.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "### 1. 准备环境\n",
    "\n",
    "%pip install pymilvus langchain langgraph langchain_openai langchain_community sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6066864-ca88-47de-badc-3cfd6eb5b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6d0118-8b79-4f06-8324-ad40625806b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置加载完毕。\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import uuid\n",
    "from typing import TypedDict, Annotated, List, Union\n",
    "import operator\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langgraph.graph import StateGraph, END\n",
    "# from langgraph.prebuilt import ToolExecutor,  ToolInvocation\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Milvus/Pymilvus related\n",
    "from pymilvus import connections, utility, CollectionSchema, FieldSchema, DataType, Collection\n",
    "\n",
    "# --- Configuration ---\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-YOUR_OPENAI_API_KEY\"\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"错误：请设置 OPENAI_API_KEY 环境变量。\")\n",
    "    # exit() # 在notebook中，我们可能不希望直接退出，而是提示用户\n",
    "\n",
    "# Milvus Connection Parameters\n",
    "MILVUS_HOST = \"localhost\" # 或者您的 Milvus 服务地址\n",
    "MILVUS_PORT = \"19530\"     # Milvus Standalone/Cluster 默认端口\n",
    "MILVUS_COLLECTION_NAME = \"ai_agent_knowledge_base\"\n",
    "MILVUS_EMBEDDING_DIM = 1536 # OpenAI ada-002 embeddings\n",
    "ID_FIELD_NAME = \"doc_id\"\n",
    "TEXT_FIELD_NAME = \"text_content\"\n",
    "VECTOR_FIELD_NAME = \"embedding\"\n",
    "\n",
    "# LLM and Embeddings\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "print(\"配置加载完毕。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd64550-511e-4d3a-9aa0-e84e8ef7af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功连接到 Milvus: localhost:19530\n",
      "集合 'ai_agent_knowledge_base' 已存在.\n",
      "知识库中已有 7 条数据，跳过示例数据插入。\n"
     ]
    }
   ],
   "source": [
    "# Milvus Setup and Helper Functions\n",
    "\n",
    "def connect_to_milvus():\n",
    "    \"\"\"建立与 Milvus 的连接\"\"\"\n",
    "    try:\n",
    "        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "        print(f\"成功连接到 Milvus: {MILVUS_HOST}:{MILVUS_PORT}\")\n",
    "    except Exception as e:\n",
    "        print(f\"连接 Milvus 失败: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_milvus_collection_if_not_exists():\n",
    "    \"\"\"如果集合不存在，则创建它\"\"\"\n",
    "    connect_to_milvus() # 确保连接\n",
    "    if utility.has_collection(MILVUS_COLLECTION_NAME):\n",
    "        print(f\"集合 '{MILVUS_COLLECTION_NAME}' 已存在.\")\n",
    "        # 可选：加载集合以备后用\n",
    "        # collection = Collection(MILVUS_COLLECTION_NAME)\n",
    "        # collection.load()\n",
    "        # print(f\"集合 '{MILVUS_COLLECTION_NAME}' 已加载.\")\n",
    "        return Collection(MILVUS_COLLECTION_NAME)\n",
    "\n",
    "    field_id = FieldSchema(name=ID_FIELD_NAME, dtype=DataType.VARCHAR, is_primary=True, max_length=36)\n",
    "    field_text = FieldSchema(name=TEXT_FIELD_NAME, dtype=DataType.VARCHAR, max_length=65535) # 存储原始文本\n",
    "    field_embedding = FieldSchema(name=VECTOR_FIELD_NAME, dtype=DataType.FLOAT_VECTOR, dim=MILVUS_EMBEDDING_DIM)\n",
    "\n",
    "    schema = CollectionSchema(\n",
    "        fields=[field_id, field_text, field_embedding],\n",
    "        description=\"AI Agent Knowledge Base collection\",\n",
    "        enable_dynamic_field=False # 如果需要额外元数据且不想预定义，可以设为True\n",
    "    )\n",
    "    collection = Collection(MILVUS_COLLECTION_NAME, schema=schema)\n",
    "    print(f\"集合 '{MILVUS_COLLECTION_NAME}' 创建成功.\")\n",
    "\n",
    "    # 为向量字段创建索引 (IVF_FLAT 是一个常用选择)\n",
    "    index_params = {\n",
    "        \"metric_type\": \"L2\", # 或 \"IP\" (Inner Product)\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128},\n",
    "    }\n",
    "    collection.create_index(field_name=VECTOR_FIELD_NAME, index_params=index_params)\n",
    "    print(f\"为字段 '{VECTOR_FIELD_NAME}' 创建索引成功.\")\n",
    "    collection.load()\n",
    "    print(f\"集合 '{MILVUS_COLLECTION_NAME}' 已加载.\")\n",
    "    return collection\n",
    "\n",
    "def insert_data_to_milvus(collection: Collection, texts: List[str]):\n",
    "    \"\"\"将文本数据向量化并插入 Milvus\"\"\"\n",
    "    if not texts:\n",
    "        print(\"没有数据需要插入。\")\n",
    "        return\n",
    "\n",
    "    print(f\"正在为 {len(texts)} 条文本生成向量...\")\n",
    "    vectors = embeddings_model.embed_documents(texts)\n",
    "    print(\"向量生成完毕。\")\n",
    "\n",
    "    # 准备插入数据\n",
    "    data_to_insert = []\n",
    "    for i, text_content in enumerate(texts):\n",
    "        data_to_insert.append({\n",
    "            ID_FIELD_NAME: str(uuid.uuid4()),\n",
    "            TEXT_FIELD_NAME: text_content,\n",
    "            VECTOR_FIELD_NAME: vectors[i]\n",
    "        })\n",
    "\n",
    "    print(f\"正在向 Milvus 集合 '{collection.name}' 插入 {len(data_to_insert)} 条数据...\")\n",
    "    insert_result = collection.insert(data_to_insert)\n",
    "    collection.flush() # 确保数据持久化\n",
    "    print(f\"数据插入成功. 影响行数: {insert_result.insert_count}\")\n",
    "    print(f\"当前集合实体数量: {collection.num_entities}\")\n",
    "\n",
    "\n",
    "# 执行 Milvus 初始化\n",
    "try:\n",
    "    knowledge_collection = create_milvus_collection_if_not_exists()\n",
    "\n",
    "    # 准备一些示例知识数据 (仅在首次运行时或需要时插入)\n",
    "    # 为避免重复插入，可以检查集合是否为空\n",
    "    if knowledge_collection.num_entities == 0:\n",
    "        print(\"知识库为空，准备插入示例数据...\")\n",
    "        sample_knowledge = [\n",
    "            \"Milvus 是一款开源的向量数据库，专为大规模向量相似性搜索和分析而设计。\",\n",
    "            \"AI Agent 可以利用 Milvus 作为其长期记忆存储和外部知识库。\",\n",
    "            \"LangGraph 是一个用于构建有状态、多参与者应用程序的库，特别适合构建复杂的 AI Agent。\",\n",
    "            \"向量数据库通过将数据转换为向量嵌入，并使用专门的索引进行高效的相似性搜索。\",\n",
    "            \"RAG (Retrieval Augmented Generation) 是一种结合了检索系统和生成模型的AI技术，可以提高生成内容的准确性和相关性。\",\n",
    "            \"太阳是太阳系的中心天体，其核心温度高达1500万摄氏度。\",\n",
    "            \"Python 是一种广泛使用的高级编程语言，以其简洁的语法和强大的库生态系统而闻名。\"\n",
    "        ]\n",
    "        insert_data_to_milvus(knowledge_collection, sample_knowledge)\n",
    "    else:\n",
    "        print(f\"知识库中已有 {knowledge_collection.num_entities} 条数据，跳过示例数据插入。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Milvus 初始化或数据插入过程中发生错误: {e}\")\n",
    "    # 在Notebook中，我们可能不希望程序因Milvus连接问题而完全停止后续单元格的执行\n",
    "    # 但后续依赖Milvus的单元格可能会失败\n",
    "    knowledge_collection = None # 标记为None，以便后续检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b4bf10b-75ab-4e1a-b4d9-0cea29e58a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangGraph App compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import List, TypedDict, Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "# 1. Define Tools\n",
    "@tool\n",
    "def search_milvus_knowledge_base(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the Milvus knowledge base for information relevant to the query.\n",
    "    The input should be a clear and specific question or search keywords.\n",
    "    \"\"\"\n",
    "    if not knowledge_collection:\n",
    "        return \"Milvus knowledge base is not available.\"\n",
    "    print(f\"\\n[Tool Call: search_milvus_knowledge_base] Query: {query}\")\n",
    "    query_vector = embeddings_model.embed_query(query)\n",
    "    \n",
    "    search_params = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"params\": {\"nprobe\": 10},  # Adjust nprobe based on index type and data size\n",
    "    }\n",
    "    \n",
    "    # Perform the search\n",
    "    results = knowledge_collection.search(\n",
    "        data=[query_vector],\n",
    "        anns_field=VECTOR_FIELD_NAME,\n",
    "        param=search_params,\n",
    "        limit=3,  # Return top 3 relevant results\n",
    "        expr=None,  # Optional filter, e.g., \"doc_type == 'faq'\"\n",
    "        output_fields=[TEXT_FIELD_NAME]  # Retrieve original text content\n",
    "    )\n",
    "    \n",
    "    context = \"\"\n",
    "    if results and results[0]:\n",
    "        context_docs = [hit.entity.get(TEXT_FIELD_NAME) for hit in results[0]]\n",
    "        context = \"\\n\".join(context_docs)\n",
    "        print(f\"[Tool Result] Found context: {context[:200]}...\")\n",
    "    else:\n",
    "        print(\"[Tool Result] No relevant context found in Milvus.\")\n",
    "        context = \"No relevant information found in the knowledge base.\"\n",
    "    return context\n",
    "\n",
    "# Define the tools list\n",
    "tools = [search_milvus_knowledge_base]\n",
    "\n",
    "# 2. Define Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]  # Accumulate messages\n",
    "\n",
    "# 3. Define Nodes\n",
    "def agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Agent node: Decides the next action (call a tool or respond directly).\n",
    "    \"\"\"\n",
    "    print(\"\\n[Node: Agent]\")\n",
    "    # Bind tools to the LLM to make it aware of available tools\n",
    "    bound_llm = llm.bind_tools(tools)\n",
    "    response = bound_llm.invoke(state[\"messages\"])\n",
    "    \n",
    "    print(f\"[Agent Decision] Response: {response.content}, Tool Calls: {response.tool_calls}\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def tool_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Tool node: Executes tool calls requested by the agent.\n",
    "    \"\"\"\n",
    "    print(\"\\n[Node: Tool Executor]\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if not hasattr(last_message, \"tool_calls\") or not last_message.tool_calls:\n",
    "        print(\"[Tool Executor] No tool calls found in the last message.\")\n",
    "        return {\"messages\": []}\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_input = tool_call[\"args\"]\n",
    "        \n",
    "        # Find the tool by name\n",
    "        tool = next((t for t in tools if t.name == tool_name), None)\n",
    "        if not tool:\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=f\"Error: Tool {tool_name} not found.\",\n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Execute the tool\n",
    "            result = tool.invoke(tool_input)\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=str(result),\n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            tool_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=f\"Error executing tool {tool_name}: {str(e)}\",\n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    print(f\"[Tool Executor] Executed tools, results: {tool_messages}\")\n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "# 4. Define Conditional Edges\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to continue to the tools node or end the workflow.\n",
    "    \"\"\"\n",
    "    print(\"\\n[Edge: should_continue]\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        print(\"[Edge Decision] Continue to 'tools'\")\n",
    "        return \"tools\"\n",
    "    print(\"[Edge Decision] End\")\n",
    "    return END\n",
    "\n",
    "# 5. Construct the Graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", RunnableLambda(agent_node))\n",
    "workflow.add_node(\"tools\", RunnableLambda(tool_node))\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "print(\"\\nLangGraph App compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ae2a001-a5ae-4bb4-8dd8-e578871c2fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 已准备就绪。开始提问吧！(输入 'exit' 退出)\n",
      "------------------------------\n",
      "\n",
      "--- 案例1: Agent 利用 Milvus 查找信息 ---\n",
      "User: Milvus 是什么?\n",
      "\n",
      "[Node: Agent]\n",
      "[Agent Decision] Response: Milvus 是一个开源的向量数据库（Vector Database），专为处理大规模向量数据的存储、检索和管理而设计。它广泛应用于人工智能、机器学习、推荐系统、图像检索、自然语言处理等领域，能够高效地进行相似性搜索（如最近邻搜索，ANN）。\n",
      "\n",
      "**主要特点包括：**\n",
      "- **高性能向量检索**：支持亿级别向量的高效相似性搜索。\n",
      "- **多种索引类型**：如 IVF、HNSW、PQ 等，适应不同场景需求。\n",
      "- **分布式架构**：支持横向扩展，适合大规模数据和高并发场景。\n",
      "- **易于集成**：提供多种客户端 SDK（如 Python、Java、Go 等），并支持 RESTful API。\n",
      "- **丰富的数据管理功能**：支持数据分区、分片、持久化等。\n",
      "\n",
      "**应用场景举例：**\n",
      "- 图像/视频/音频检索\n",
      "- 文本语义搜索\n",
      "- 推荐系统\n",
      "- 生物信息学中的基因相似性分析\n",
      "\n",
      "Milvus 由 Zilliz 公司主导开发，并已成为 LF AI & Data 基金会的孵化项目。它在全球范围内拥有大量用户和活跃的开源社区。, Tool Calls: []\n",
      "\n",
      "[Edge: should_continue]\n",
      "[Edge Decision] End\n",
      "--- Event for Node: agent ---\n",
      "AI: Milvus 是一个开源的向量数据库（Vector Database），专为处理大规模向量数据的存储、检索和管理而设计。它广泛应用于人工智能、机器学习、推荐系统、图像检索、自然语言处理等领域，能够高效地进行相似性搜索（如最近邻搜索，ANN）。\n",
      "\n",
      "**主要特点包括：**\n",
      "- **高性能向量检索**：支持亿级别向量的高效相似性搜索。\n",
      "- **多种索引类型**：如 IVF、HNSW、PQ 等，适应不同场景需求。\n",
      "- **分布式架构**：支持横向扩展，适合大规模数据和高并发场景。\n",
      "- **易于集成**：提供多种客户端 SDK（如 Python、Java、Go 等），并支持 RESTful API。\n",
      "- **丰富的数据管理功能**：支持数据分区、分片、持久化等。\n",
      "\n",
      "**应用场景举例：**\n",
      "- 图像/视频/音频检索\n",
      "- 文本语义搜索\n",
      "- 推荐系统\n",
      "- 生物信息学中的基因相似性分析\n",
      "\n",
      "Milvus 由 Zilliz 公司主导开发，并已成为 LF AI & Data 基金会的孵化项目。它在全球范围内拥有大量用户和活跃的开源社区。\n",
      "----------\n",
      "\n",
      "--- 案例2: Agent 回答一个不需要查知识库的问题 (可能直接回答或拒绝) ---\n",
      "User: 你好吗？\n",
      "\n",
      "[Node: Agent]\n",
      "[Agent Decision] Response: 你好！我很好，谢谢你的关心。有什么我可以帮你的吗？, Tool Calls: []\n",
      "\n",
      "[Edge: should_continue]\n",
      "[Edge Decision] End\n",
      "AI: 你好！我很好，谢谢你的关心。有什么我可以帮你的吗？\n",
      "\n",
      "--- 概念演示: 存储对话到 Milvus (作为记忆) ---\n",
      "准备将以下对话片段存入记忆库:\n",
      "用户问: Milvus 是什么?\n",
      "Agent答: Milvus 是一款先进的开源向量数据库，非常适合AI应用中的大规模相似性搜索。它能帮助Agent快速从大量文档中找到相关信息。\n",
      "注意: 实际应用中，对话记忆应存入专用集合或分区。此处为演示，插入当前知识库。\n",
      "正在为 1 条文本生成向量...\n",
      "向量生成完毕。\n",
      "正在向 Milvus 集合 'ai_agent_knowledge_base' 插入 1 条数据...\n",
      "数据插入成功. 影响行数: 1\n",
      "当前集合实体数量: 8\n",
      "对话片段已（概念性地）存入 Milvus 记忆库。\n",
      "\n",
      "新用户查询: 介绍一下向量数据库\n",
      "Agent (概念上) 将搜索 Milvus 记忆库以查找相似历史对话...\n",
      "\n",
      "[Tool Call: search_milvus_knowledge_base] Query: 介绍一下向量数据库\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2376267/2063415455.py:100: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_memories = search_milvus_knowledge_base(new_user_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool Result] Found context: 向量数据库通过将数据转换为向量嵌入，并使用专门的索引进行高效的相似性搜索。\n",
      "Milvus 是一款开源的向量数据库，专为大规模向量相似性搜索和分析而设计。\n",
      "用户问: Milvus 是什么?\n",
      "Agent答: Milvus 是一款先进的开源向量数据库，非常适合AI应用中的大规模相似性搜索。它能帮助Agent快速从大量文档中找到相关信息。...\n",
      "从Milvus中召回的（模拟的）相关记忆/知识:\n",
      "向量数据库通过将数据转换为向量嵌入，并使用专门的索引进行高效的相似性搜索。\n",
      "Milvus 是一款开源的向量数据库，专为大规模向量相似性搜索和分析而设计。\n",
      "用户问: Milvus 是什么?\n",
      "Agent答: Milvus 是一款先进的开源向量数据库，非常适合AI应用中的大规模相似性搜索。它能帮助Agent快速从大量文档中找到相关信息。\n"
     ]
    }
   ],
   "source": [
    "# Run the Agent and Interact\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ or not knowledge_collection:\n",
    "    print(\"无法运行 Agent：请确保 OpenAI API 密钥已设置，并且 Milvus 连接和集合初始化成功。\")\n",
    "else:\n",
    "    print(\"Agent 已准备就绪。开始提问吧！(输入 'exit' 退出)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 演示 Agent 使用 Milvus 作为外部知识库\n",
    "    print(\"\\n--- 案例1: Agent 利用 Milvus 查找信息 ---\")\n",
    "    query1 = \"Milvus 是什么?\"\n",
    "    print(f\"User: {query1}\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=query1)]}\n",
    "    \n",
    "    # 使用 stream 方法逐步查看执行过程\n",
    "    for event in app.stream(inputs):\n",
    "        for key, value in event.items():\n",
    "            print(f\"--- Event for Node: {key} ---\")\n",
    "            if \"messages\" in value:\n",
    "                # 打印最新消息的内容\n",
    "                latest_message = value[\"messages\"][-1]\n",
    "                if isinstance(latest_message, AIMessage):\n",
    "                    print(f\"AI: {latest_message.content}\")\n",
    "                    if latest_message.tool_calls:\n",
    "                        print(f\"AI requests tool call: {latest_message.tool_calls}\")\n",
    "                elif isinstance(latest_message, ToolMessage):\n",
    "                    print(f\"Tool Result ({latest_message.tool_call_id}): {latest_message.content}\")\n",
    "                else:\n",
    "                    print(f\"Message ({type(latest_message).__name__}): {latest_message.content}\")\n",
    "        print(\"-\" * 10)\n",
    "    \n",
    "    print(\"\\n--- 案例2: Agent 回答一个不需要查知识库的问题 (可能直接回答或拒绝) ---\")\n",
    "    query2 = \"你好吗？\"\n",
    "    print(f\"User: {query2}\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=query2)]}\n",
    "    # 获取最终结果\n",
    "    final_response = app.invoke(inputs)\n",
    "    if final_response and \"messages\" in final_response and final_response[\"messages\"]:\n",
    "        print(f\"AI: {final_response['messages'][-1].content}\")\n",
    "    else:\n",
    "        print(\"AI 未能生成回复。\")\n",
    "\n",
    "    # 演示 Agent 存储对话片段向量 (概念性，实际存储逻辑需要更完善)\n",
    "    # 假设 query1 和其最终回复是一个需要记忆的片段\n",
    "    if final_response and \"messages\" in final_response: # 使用上一个交互的结果\n",
    "        print(\"\\n--- 概念演示: 存储对话到 Milvus (作为记忆) ---\")\n",
    "        # 假设我们想要将用户的问题和Agent的最终回答作为一个记忆单元\n",
    "        # 这里的 final_response['messages'] 可能包含整个对话历史\n",
    "        # 我们通常取最后的用户问题和AI回答对\n",
    "        \n",
    "        # 找到 query1 对应的最终 AIMessage\n",
    "        # 这是一个简化的查找，实际中可能需要更复杂的逻辑来配对问答\n",
    "        q1_final_answer = \"\"\n",
    "        # 假设 app.invoke 返回的 messages 列表的最后一个是最终答案\n",
    "        if final_response['messages'] and isinstance(final_response['messages'][-1], AIMessage):\n",
    "             q1_final_answer = final_response['messages'][-1].content # 取决于上一个 invoke 的内容\n",
    "        \n",
    "        # 如果 query1 导致了工具调用，我们可能需要从 stream 中找到它的最终回答\n",
    "        # 为了简化，我们直接使用上面交互中打印的最终回答\n",
    "        # 真实场景下，我们会捕获 app.invoke(inputs1) 的最终 AIMessage\n",
    "\n",
    "        # 假设我们已经有了 query1 和 agent_final_answer_to_query1\n",
    "        # 这里我们手动设置一个示例，因为上面app.invoke(inputs)的最终结果是针对query2的\n",
    "        # 如果要精确获取query1的最终回答，需要重新运行app.invoke针对query1\n",
    "        # 或者从 app.stream 的事件中提取\n",
    "        \n",
    "        # 为了演示，我们假设第一个问题\"Milvus是什么\"的最终答案是 \"Milvus是一个开源的向量数据库...\" (由LLM结合搜索结果生成)\n",
    "        # 实际上，这个答案会在 stream 的某个 AIMessage 中出现\n",
    "        # 这里我们模拟一下，因为直接从上面的 stream 中捕获最终答案有点复杂\n",
    "        # 理想情况下，我们会有一个明确的 \"final_answer\" 状态或消息类型\n",
    "        \n",
    "        # 假设我们通过某种方式获取到了 query1 的最终AI回答\n",
    "        simulated_final_answer_to_query1 = \"Milvus 是一款先进的开源向量数据库，非常适合AI应用中的大规模相似性搜索。它能帮助Agent快速从大量文档中找到相关信息。\" # 这是一个模拟的最终回答\n",
    "\n",
    "        if simulated_final_answer_to_query1:\n",
    "            memory_text = f\"用户问: {query1}\\nAgent答: {simulated_final_answer_to_query1}\"\n",
    "            print(f\"准备将以下对话片段存入记忆库:\\n{memory_text}\")\n",
    "            \n",
    "            # 为了避免与知识库冲突，可以存入不同的集合或使用分区\n",
    "            # 这里简单演示存入同一个集合，实际应用中应分开\n",
    "            try:\n",
    "                # 为简化，我们假设有一个单独的记忆集合 memory_collection\n",
    "                # memory_collection = create_milvus_collection_if_not_exists(\"ai_agent_memory\", ...)\n",
    "                # insert_data_to_milvus(memory_collection, [memory_text])\n",
    "                # 由于我们这里只有一个集合，就直接插入到 knowledge_collection，并作说明\n",
    "                print(\"注意: 实际应用中，对话记忆应存入专用集合或分区。此处为演示，插入当前知识库。\")\n",
    "                insert_data_to_milvus(knowledge_collection, [memory_text])\n",
    "                print(\"对话片段已（概念性地）存入 Milvus 记忆库。\")\n",
    "\n",
    "                # 如何在新对话开始时搜索相似历史 -> 召回相关记忆\n",
    "                new_user_query = \"介绍一下向量数据库\" # 一个新的，但与之前记忆相关的问题\n",
    "                print(f\"\\n新用户查询: {new_user_query}\")\n",
    "                print(\"Agent (概念上) 将搜索 Milvus 记忆库以查找相似历史对话...\")\n",
    "                # 实际操作：\n",
    "                # 1. new_user_query_vector = embeddings_model.embed_query(new_user_query)\n",
    "                # 2. search memory_collection with new_user_query_vector\n",
    "                # 3. retrieved_memories = results_from_memory_collection\n",
    "                # 4. Agent 使用 retrieved_memories 作为上下文辅助当前对话\n",
    "                # 这里我们用知识库搜索来模拟这个过程：\n",
    "                retrieved_memories = search_milvus_knowledge_base(new_user_query)\n",
    "                print(f\"从Milvus中召回的（模拟的）相关记忆/知识:\\n{retrieved_memories}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"存储或检索记忆时发生错误: {e}\")\n",
    "        else:\n",
    "            print(\"未能获取到 query1 的最终回答，跳过记忆存储演示。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610a7f4-a141-461b-aa9d-e86ab8e4a4bb",
   "metadata": {},
   "source": [
    "## 讨论：Milvus 如何赋能 Agent 更智能地执行任务\n",
    "\n",
    "Milvus 通过其强大的向量存储和检索能力，可以从多个方面赋能 AI Agent，使其更智能：\n",
    "\n",
    "1.  **增强的知识获取与利用:**\n",
    "    *   **海量知识管理:** Agent 可以接入存储在 Milvus 中的大规模、多样化的外部知识，不再局限于模型预训练数据。\n",
    "    *   **语义理解:** 通过向量相似性搜索，Agent 能够理解查询的深层语义，而不是简单的关键词匹配，从而找到更相关的知识。\n",
    "    *   **动态知识更新:** Milvus 中的知识库可以随时更新，Agent 可以即时获取最新的信息，保持知识的时效性。\n",
    "\n",
    "2.  **更强大的记忆能力:**\n",
    "    *   **长期记忆的实现:** Milvus 为 Agent 提供了存储和检索长期记忆（如对话历史、用户偏好、学习经验）的有效机制。\n",
    "    *   **情境感知与个性化:** 通过检索相似的过去交互，Agent 可以更好地理解当前对话的上下文，提供更连贯和个性化的服务。例如，记住用户之前的选择或问题。\n",
    "    *   **持续学习与改进:** Agent 可以将成功的交互模式或解决问题的策略向量化存储，未来遇到类似情况时可以快速借鉴，实现持续学习和性能提升。\n",
    "\n",
    "3.  **提升任务执行效率与效果:**\n",
    "    *   **快速信息检索:** Milvus 的高效检索能力确保 Agent 能够迅速找到所需信息，减少任务执行的延迟。\n",
    "    *   **复杂问题解决:** 对于需要多方面知识的复杂问题，Agent 可以从 Milvus 中检索多个相关的知识片段，综合分析后给出答案。\n",
    "    *   **减少幻觉:** 通过 RAG 模式，Agent 的回答基于从 Milvus 检索到的实际数据，可以显著减少“幻觉”现象，提高回答的准确性和可靠性。\n",
    "\n",
    "4.  **支持更复杂的 Agent 行为:**\n",
    "    *   **主动学习与探索:** Agent 可以将探索到的新知识、新环境信息向量化存入 Milvus，用于未来的规划和决策。\n",
    "    *   **多 Agent 协作:** 多个 Agent 可以共享同一个 Milvus 实例作为知识或记忆中心，促进协作和知识共享。\n",
    "\n",
    "总之，Milvus 为 AI Agent 提供了一个坚实的数据基础，使其能够更有效地存储、管理和利用信息，从而在理解、规划、学习和交互等各个方面表现得更加智能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c256b-f0f5-4954-b77a-469cb089fc78",
   "metadata": {},
   "source": [
    "## Hands-on Exercise 3: 实操AI Agent Demo\n",
    "\n",
    "**目标:** 体验并扩展我们刚刚构建的 AI Agent。\n",
    "\n",
    "**任务:**\n",
    "\n",
    "1.  **运行并理解 Agent:**\n",
    "    *   确保你的 OpenAI API Key 已正确设置，并且 Milvus 服务正在运行。\n",
    "    *   逐个执行上面的 Jupyter Notebook 单元格。\n",
    "    *   观察 Agent 在处理不同类型问题时的行为：\n",
    "        *   哪些问题触发了 `search_milvus_knowledge_base` 工具？\n",
    "        *   Agent 如何利用从 Milvus 返回的信息来构建答案？\n",
    "        *   Agent 如何处理不需要外部知识的问题？\n",
    "    *   仔细阅读 `app.stream(inputs)` 的输出，理解 LangGraph 中节点的流转过程。\n",
    "\n",
    "2.  **扩展知识库:**\n",
    "    *   在 `Cell 3` (Milvus Setup and Helper Functions) 中，找到 `sample_knowledge` 列表。\n",
    "    *   向该列表添加几条你自定义的知识条目（例如，关于某个特定技术、历史事件或你感兴趣的任何主题）。\n",
    "        *   **重要:** 添加新知识后，你需要一种方式来重新运行 `insert_data_to_milvus` 函数。你可以：\n",
    "            *   简单地删除 Milvus collection（如果只是测试），然后重新创建并插入所有数据：`utility.drop_collection(MILVUS_COLLECTION_NAME)`（请谨慎操作！）。\n",
    "            *   或者，修改代码，使其只插入新的、尚未存在的条目（这更复杂，需要检查数据是否已存在）。\n",
    "            *   对于本练习，最简单的方法是：如果 `knowledge_collection.num_entities > 0`，先 `utility.drop_collection(MILVUS_COLLECTION_NAME)`，然后再调用 `create_milvus_collection_if_not_exists()` 和 `insert_data_to_milvus()`。**请注意，这将删除所有现有数据。**\n",
    "    *   重新运行相关的单元格以更新 Milvus 中的数据。\n",
    "    *   向 Agent 提问，测试它是否能利用你新添加的知识。\n",
    "\n",
    "3.  **(可选) 尝试不同的查询:**\n",
    "    *   构造一些更复杂的查询，看看 Agent 如何响应。\n",
    "    *   尝试一些模棱两可的查询，观察 Agent 是否会尝试澄清或依赖其内部知识。\n",
    "\n",
    "4.  **(进阶可选) 添加一个新的简单工具:**\n",
    "    *   例如，添加一个 `get_current_time` 工具，它不查询 Milvus，只是返回当前时间。\n",
    "        ```python\n",
    "        from datetime import datetime\n",
    "\n",
    "        @tool\n",
    "        def get_current_time(placeholder: str = \"default\") -> str: # Langchain tools often expect an input arg\n",
    "            \"\"\"Returns the current date and time.\"\"\"\n",
    "            print(\"\\n[Tool Call: get_current_time]\")\n",
    "            return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        ```\n",
    "    *   将这个新工具添加到 `Cell 4` 的 `tools` 列表中: `tools = [search_milvus_knowledge_base, get_current_time]`。\n",
    "    *   重新编译 `app = workflow.compile()`。\n",
    "    *   向 Agent 提问，例如 \"现在几点了？\"，看看它是否会使用这个新工具。\n",
    "\n",
    "**思考与记录:**\n",
    "\n",
    "*   在操作过程中遇到了哪些问题？你是如何解决的？\n",
    "*   你认为 Milvus 在这个 Agent 中最大的价值是什么？\n",
    "*   如果让你进一步改进这个 Agent，你会从哪些方面入手？（例如，更精细的记忆管理、更复杂的规划逻辑、更多的工具等）\n",
    "\n",
    "祝你实验愉快！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82af8e-b48c-498a-82ff-977fd22a3ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ad6d5-a4ba-4c63-867c-6f54d07a4d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b705a-ff6c-47cc-be7a-c93e602f9efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d5a70-8b05-4bad-92ed-a082b1216be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
